services:
  mongo:
    image: mongo:6
    container_name: mongo
    ports: ["27017:27017"]
    command: ["--replSet","rs0","--bind_ip_all"]
    volumes:
      - mongo_data:/data/db
      - ./init/init-replica.sh:/docker-entrypoint-initdb.d/init-replica.sh:ro
    healthcheck:
      test: ["CMD","mongosh","--eval","db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 20

  # Service to ensure MongoDB replica set is initialized
  mongo-init:
    image: mongo:6
    container_name: mongo-init
    depends_on:
      mongo:
        condition: service_healthy
    volumes:
      - ./init/init-replica.sh:/init-replica.sh:ro
    command: bash /init-replica.sh
    restart: "no"

  zookeeper:
    # Use the official Zookeeper image since the Bitnami 3.9 manifest is missing on the registry.
    image: zookeeper:3.9
    environment: { ALLOW_ANONYMOUS_LOGIN: "yes" }
    ports: ["2181:2181"]

  kafka:
    # Use Confluent Community Platform Kafka image which is widely available on Docker Hub.
    # This replaces Bitnami image because Bitnami Kafka tags are missing in the registry for your environment.
    image: confluentinc/cp-kafka:7.4.0
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      # Listen on all interfaces inside container
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      # Advertise the container name and standard port so other services in the compose network can reach it
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Reduce replication requirements for single-node dev environment
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    ports: ["9092:9092"]

  api:
    build: ./api
    container_name: api
    ports: ["8000:8000"]
    environment:
      MONGO_URI: mongodb://mongo:27017/?replicaSet=rs0
      KAFKA_BOOTSTRAP: kafka:9092
      INFER_URL: http://phobert-infer:5000/predict
    depends_on:
      mongo-init:
        condition: service_completed_successfully
      kafka:
        condition: service_started

  phobert-infer:
    build: ./phobert-infer
    container_name: phobert-infer
    ports: ["9000:5000"]
    environment:
      MODEL_ID: wonrax/phobert-base-vietnamese-sentiment
      DEVICE: cuda
    # Use deploy.resources syntax for GPU in Compose v2+
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]





  ui:
    build: ./ui
    container_name: ui
    ports: ["8501:8501"]
    environment:
      API_BASE: http://api:8000
      MONGO_URI: mongodb://mongo:27017/?replicaSet=rs0
      INFER_URL: http://phobert-infer:5000
    depends_on:
      api:
        condition: service_started
      mongo-init:
        condition: service_completed_successfully
      phobert-infer:
        condition: service_started

  # Optional: Background HTML crawler service (disabled due to MongoDB connection issues)
  # crawler-html:
  #   build: ./crawler-html
  #   container_name: crawler-html
  #   environment:
  #     MONGO_URI: mongodb://mongo:27017/?replicaSet=rs0
  #     HEADLESS: "1"
  #     RATE_PER_MIN: "60"
  #     PROXY_LIST: ""
  #   depends_on: [mongo]

  # Apache Flink Services - Replace Spark Streaming
  flink-jobmanager:
    build: ./flink-job
    container_name: flink-jobmanager
    ports:
      - "8081:8081"  # Flink Web UI
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    command: jobmanager
    volumes:
      - flink_data:/tmp/flink-checkpoints-directory
      - flink_data:/tmp/flink-savepoints-directory
    depends_on:
      kafka:
        condition: service_started
      mongo-init:
        condition: service_completed_successfully

  flink-taskmanager:
    build: ./flink-job
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - TASK_MANAGER_NUMBER_OF_TASK_SLOTS=2
    command: taskmanager
    volumes:
      - flink_data:/tmp/flink-checkpoints-directory
      - flink_data:/tmp/flink-savepoints-directory

  # Submit Flink job automatically
  flink-job-submit:
    build: ./flink-job
    container_name: flink-job-submit
    depends_on:
      flink-jobmanager:
        condition: service_started
      flink-taskmanager:
        condition: service_started
      kafka:
        condition: service_started
      mongo-init:
        condition: service_completed_successfully
      phobert-infer:
        condition: service_started
    command: >
      bash -c "
        echo '‚è≥ Waiting for Flink cluster to be ready...' &&
        sleep 45 &&
        echo 'üöÄ Trying to submit proper Flink job...' &&
        cd /opt/flink/usrlib &&
        bash advanced_submit.sh
      "
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - KAFKA_BOOTSTRAP=kafka:9092
      - MONGO_URI=mongodb://mongo:27017/?replicaSet=rs0
      - PHOBERT_URL=http://phobert-infer:5000/predict

volumes:
  mongo_data:
  flink_data:
